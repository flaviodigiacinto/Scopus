"""
Created on Fri Jan 27 11:08:02 2023

@author: digia
"""

from datetime import datetime, timedelta
import pandas as pd
from pybliometrics.scopus import AuthorRetrieval
from docx import Document
from pybliometrics.scopus import AbstractRetrieval
from docx2pdf import convert


def Article_xlsx(df_art,path_save):
    df_art['DOI']=df_art['DOI'].fillna('')
    df_art['id'] = df_art.apply(lambda x: f"{x['Articoli']}_{x['DOI']}", axis=1)
   
    # Keep only the row with the maximum value in Citations colummn for each group of duplicates
    df_art['Citations'] = pd.to_numeric(df_art['Citations'])
    result = df_art.loc[df_art.groupby(by='id')['Citations'].idxmax()]
   
    # Drop the 'id' column
    result = result.drop(columns=['id','Author'])
    result = result.reset_index(drop=True)
   
    # WARNING: modify the following path to save the file outside your working dir
    result.to_excel(path_save+'Articoli.xlsx', sheet_name='Sheet1', index=False)
    return(result)

def Researchers_metrics(df_art,df,path_save):
    # df = pd.read_excel(path,dtype={"Scopus_ID1": str,"Scopus_ID2": str,"Scopus_ID3": str,"Scopus_ID4": str})
    df_art[["Date"]] = df_art[["Date"]].apply(pd.to_datetime)
    today = datetime.today().date()
    monthago=today-timedelta(days=30)
    yearago=today-timedelta(days=365)
    df_art['DOI']=df_art['DOI'].fillna('')
    df_art['id'] = df_art.apply(lambda x: f"{x['Articoli']}_{x['DOI']}", axis=1)
   
    # Keep only the row with the maximum value in col3 for each group of duplicates
    df_art['Citations'] = pd.to_numeric(df_art['Citations'])
    result = df_art.loc[df_art.groupby(by='id')['Citations'].idxmax()]
   
    # Drop the 'id' column
    result = result.drop(columns=['id','Author'])
    result = result.reset_index(drop=True)
    result['Article_ID']=range(len(result))
    result['Whole_Art_inf']=result['Articoli']+",_"+result['Journal']+",_DOI:"+result['DOI']
   
   
    df_p=df.copy()
    df_p = df_p.drop(columns=['Qualifica', 'Codice Nuovo Ssd',
            'Descrizione Nuovo Ssd'])
   
    df1=df_p.copy()
    df2=df_p.copy()
    df3=df_p.copy()
    df4=df_p.copy()
   
   
    df1 = df1.drop(columns=['Scopus_ID2','Scopus_ID3','Scopus_ID4'])
    df1 = df1.rename(columns={'Scopus_ID1': 'Scopus_ID'})
    df2 = df2.drop(columns=['Scopus_ID1','Scopus_ID3','Scopus_ID4'])
    df2 = df2.rename(columns={'Scopus_ID2': 'Scopus_ID'})
    df3 = df3.drop(columns=['Scopus_ID2','Scopus_ID1','Scopus_ID4'])
    df3 = df3.rename(columns={'Scopus_ID3': 'Scopus_ID'})
    df4 = df4.drop(columns=['Scopus_ID2','Scopus_ID1','Scopus_ID3'])
    df4 = df4.rename(columns={'Scopus_ID4': 'Scopus_ID'})
   
    df_new = pd.merge(df1, df2,  how='outer', left_on=['Scopus_ID','Cognome','Nome'], right_on = ['Scopus_ID','Cognome','Nome'], indicator=False)
    df_new = pd.merge(df_new, df3,  how='outer', left_on=['Scopus_ID','Cognome','Nome'], right_on = ['Scopus_ID','Cognome','Nome'], indicator=False)
    df_new = pd.merge(df_new, df4,  how='outer', left_on=['Scopus_ID','Cognome','Nome'], right_on = ['Scopus_ID','Cognome','Nome'], indicator=False)
   
    df_new.dropna(inplace=True)
    df_split = result.assign(Authors_ID=result['Authors_ID'].str.split(';'))
    new_df = df_split.explode('Authors_ID')
    new_df_filtered = new_df[new_df['Authors_ID'].isin(df_new['Scopus_ID'])]
    df_IDs=df.copy()
    df_IDs = df_IDs.drop(columns=['Cognome','Nome'])
    df['Citations'] = pd.Series(dtype='int')
    df['h_index'] = pd.Series(dtype='int')
    df['Articles'] = pd.Series(dtype='int')
    df['Articles'] = pd.Series(dtype='int')
    df['#Articles_last_year'] = pd.Series(dtype='int')
    df['Articles_last_year'] = pd.Series(dtype='str')
    df['#Articles_last_month'] = pd.Series(dtype='int')
    df['Articles_last_month'] = pd.Series(dtype='str')



    for i in range (0,len(df_IDs)):
        row_to_copy = df_IDs.loc[i]
        mask = new_df_filtered['Authors_ID'].isin(row_to_copy)
        df_filtered = new_df_filtered[mask]
        df.loc[i,'Citations']=df_filtered.Citations.sum()
        df.loc[i,'Articles']=len(df_filtered)
        df.loc[i,'h_index']=sum(x >= i + 1 for i, x in enumerate(sorted(  list(df_filtered.Citations), reverse=True)))
        df.loc[i,'#Articles_last_year'] = len(df_filtered[(df_filtered['Date'].dt.date >= yearago) & (df_filtered['Date'].dt.date <= today)])
        df.loc[i,'#Articles_last_month'] = len(df_filtered[(df_filtered['Date'].dt.date >= monthago) & (df_filtered['Date'].dt.date <= today)])
        df.loc[i,'Articles_last_year'] =(df_filtered[(df_filtered['Date'].dt.date >= yearago) & (df_filtered['Date'].dt.date <= today)])['Whole_Art_inf'].str.cat(sep=';')
        df.loc[i,'Articles_last_month'] =(df_filtered[(df_filtered['Date'].dt.date >= monthago) & (df_filtered['Date'].dt.date <= today)])['Whole_Art_inf'].str.cat(sep=';')
   
    # WARNING: modify the following path to save the file outside your working dir
    df.to_excel(path_save+'Metriche_ricercatori.xlsx', sheet_name='Sheet1', index=False)  

def Genera_Report(path_recent,Artdf,pathn,path_save):       
    df_res=Researchers_list(pathn)
    df = pd.read_excel(path_recent+'Articoli_recenti.xlsx')
    today = datetime.today().date()
    recent=today-timedelta(days=30)
    recent2=today+timedelta(days=40)
    Artdf[["Date"]] = Artdf[["Date"]].apply(pd.to_datetime)
    df_filtered=df[(df['Date'].dt.date >= recent)]
    df_filtered2=Artdf[(Artdf['Date'].dt.date>=recent)]
    df_filtered2=df_filtered2[(df_filtered2['Date'].dt.date<=recent2)]
    df_filtered2.to_excel(path_save+'Articoli_recenti.xlsx', sheet_name='Sheet1', index=False)
    merged_df = pd.merge(df_filtered2, df_filtered[['Articoli']], on='Articoli', how='left', indicator=True)
    result_df = merged_df[merged_df['_merge'] == 'left_only'].drop(columns='_merge')
    
    document = Document()
    TestName='Articoli UCSC Recenti'
    title=document.add_paragraph()
    title.add_run(TestName).bold=True
    
    document.add_paragraph()
    
    for index, row in result_df.iterrows():
        DOIn=row['DOI']
        title=row['Articoli']        
        ab = AbstractRetrieval(DOIn, view='FULL')
        Journal=ab.publicationName
        text='  - '+ title+', '
        paragraph = document.add_paragraph()
        paragraph.add_run(text)
        bold_run = paragraph.add_run((Journal))
        bold_run.bold = True
        #' DOI:'+row['DOI']
        for Auth in ab.authors:
            if (df_res['Scopus_ID'].eq(str(Auth[0]))).any():
                paragraph.add_run(', ')
                underlined_run = paragraph.add_run((Auth[1]))
                underlined_run.underline = True
            else:
                paragraph.add_run(', '+str(Auth[1]))
               
        paragraph.add_run(', '+DOIn)  
        document.add_paragraph()     
    
    document.save(path_save+'Pubblicazioni_Recenti.docx') 
    convert(path_save+'Pubblicazioni_Recenti.docx', path_save+"Pubblicazioni_Recenti.pdf")

def Genera_Report_xSSD(path_recent,Artdf,pathn,path_save):       
    df_res=Researchers_list(pathn)
    df = pd.read_excel(path_recent+'Articoli_recenti.xlsx')
    today = datetime.today().date()
    recent=today-timedelta(days=30)
    recent2=today+timedelta(days=40)
    Artdf[["Date"]] = Artdf[["Date"]].apply(pd.to_datetime)
    df_filtered=df[(df['Date'].dt.date >= recent)]
    df_filtered2=Artdf[(Artdf['Date'].dt.date>=recent)]
    df_filtered2=df_filtered2[(df_filtered2['Date'].dt.date<=recent2)]
    df_filtered2.to_excel(path_save+'Articoli_recenti.xlsx', sheet_name='Sheet1', index=False)
    merged_df = pd.merge(df_filtered2, df_filtered[['Articoli']], on='Articoli', how='left', indicator=True)
    result_df = merged_df[merged_df['_merge'] == 'left_only'].drop(columns='_merge')
    
    unique_values = df_res['Descrizione Nuovo Ssd'].unique()
    
    document = Document()
    TestName='Articoli UCSC Recenti - SSD'
    title=document.add_paragraph()
    title.add_run(TestName).bold=True
    
    document.add_paragraph()
    
    for rows in unique_values:
        df_f = df_res[df_res['Descrizione Nuovo Ssd'] == rows]
        df_f2 = result_df[result_df['Authors_ID'].str.contains('|'.join(df_f['Scopus_ID'].tolist()))]
        if df_f2.empty is False:
            text=rows
            paragraph = document.add_paragraph()
            bold_run = paragraph.add_run((text))
            bold_run.bold = True
            for index, row in df_f2.iterrows(): 
                DOIn=row['DOI']
                title=row['Articoli']        
                ab = AbstractRetrieval(DOIn, view='FULL')
                Journal=ab.publicationName
                text='  - '+ title+', '
                paragraph = document.add_paragraph()
                paragraph.add_run(text)
                bold_run = paragraph.add_run((Journal))
                bold_run.bold = True
                #' DOI:'+row['DOI']
                for Auth in ab.authors:
                    if (df_f['Scopus_ID'].eq(str(Auth[0]))).any():
                        paragraph.add_run(', ')
                        underlined_run = paragraph.add_run((Auth[1]))
                        underlined_run.underline = True
                    else:
                        paragraph.add_run(', '+str(Auth[1]))
               
                paragraph.add_run(', '+DOIn)  
                document.add_paragraph()
    
    document.save(path_save+'Pubblicazioni_Recenti_SSD.docx') 
    convert(path_save+'Pubblicazioni_Recenti_SSD.docx', path_save+"Pubblicazioni_Recenti_SSD.pdf")


    
def Researchers_list(pathn):
    df = pd.read_excel(path,dtype={"Scopus_ID1": str,"Scopus_ID2": str,"Scopus_ID3": str,"Scopus_ID4": str})
    df1=df.copy()
    df2=df.copy()
    df3=df.copy()
    df4=df.copy()
    
    df_p=df.copy()
    df_p = df_p.drop(columns=['Qualifica', 'Codice Nuovo Ssd'])
    
    df1=df_p.copy()
    df2=df_p.copy()
    df3=df_p.copy()
    df4=df_p.copy()
    
    df1 = df1.drop(columns=['Scopus_ID2','Scopus_ID3','Scopus_ID4'])
    df1 = df1.rename(columns={'Scopus_ID1': 'Scopus_ID'})
    df2 = df2.drop(columns=['Scopus_ID1','Scopus_ID3','Scopus_ID4'])
    df2 = df2.rename(columns={'Scopus_ID2': 'Scopus_ID'})
    df3 = df3.drop(columns=['Scopus_ID2','Scopus_ID1','Scopus_ID4'])
    df3 = df3.rename(columns={'Scopus_ID3': 'Scopus_ID'})
    df4 = df4.drop(columns=['Scopus_ID2','Scopus_ID1','Scopus_ID3'])
    df4 = df4.rename(columns={'Scopus_ID4': 'Scopus_ID'})
    
    df_new = pd.merge(df1, df2,  how='outer', left_on=['Scopus_ID','Cognome','Nome','Descrizione Nuovo Ssd'], right_on = ['Scopus_ID','Cognome','Nome','Descrizione Nuovo Ssd'], indicator=False)
    df_new = pd.merge(df_new, df3,  how='outer', left_on=['Scopus_ID','Cognome','Nome','Descrizione Nuovo Ssd'], right_on = ['Scopus_ID','Cognome','Nome','Descrizione Nuovo Ssd'], indicator=False)
    df_new = pd.merge(df_new, df4,  how='outer', left_on=['Scopus_ID','Cognome','Nome','Descrizione Nuovo Ssd'], right_on = ['Scopus_ID','Cognome','Nome','Descrizione Nuovo Ssd'], indicator=False)
    
    df_new.dropna(inplace=True)
    return df_new    
    
# WARNING: modify the following path to get the Ricercatori.xlsx file from your path
path="Ricercatori.xlsx"
# WARNING: modify the following path to get the Articoli_recenti.xlsx file from your path
path_recent="C:/Users/digia/OneDrive/Desktop/Codes/Python_Scripts/Scopus/Report/Report_29032023/"
#Change here if you want to change the path for saving the report
path_save='C:/Users/digia/OneDrive/Desktop/Codes/Python_Scripts/Scopus/Report/Report_05042023/'

# Read the CSV file from a URL into a DataFrame
df = pd.read_excel(path,dtype={"Scopus_ID1": str,"Scopus_ID2": str,"Scopus_ID3": str,"Scopus_ID4": str})

df_p=df.copy()
df_p = df_p.drop(columns=['Qualifica', 'Codice Nuovo Ssd',
       'Descrizione Nuovo Ssd'])

df1=df_p.copy()
df2=df_p.copy()
df3=df_p.copy()
df4=df_p.copy()

df1 = df1.drop(columns=['Scopus_ID2','Scopus_ID3','Scopus_ID4'])
df1 = df1.rename(columns={'Scopus_ID1': 'Scopus_ID'})
df2 = df2.drop(columns=['Scopus_ID1','Scopus_ID3','Scopus_ID4'])
df2 = df2.rename(columns={'Scopus_ID2': 'Scopus_ID'})
df3 = df3.drop(columns=['Scopus_ID2','Scopus_ID1','Scopus_ID4'])
df3 = df3.rename(columns={'Scopus_ID3': 'Scopus_ID'})
df4 = df4.drop(columns=['Scopus_ID2','Scopus_ID1','Scopus_ID3'])
df4 = df4.rename(columns={'Scopus_ID4': 'Scopus_ID'})

df_new = pd.merge(df1, df2,  how='outer', left_on=['Scopus_ID','Cognome','Nome'], right_on = ['Scopus_ID','Cognome','Nome'], indicator=False)
df_new = pd.merge(df_new, df3,  how='outer', left_on=['Scopus_ID','Cognome','Nome'], right_on = ['Scopus_ID','Cognome','Nome'], indicator=False)
df_new = pd.merge(df_new, df4,  how='outer', left_on=['Scopus_ID','Cognome','Nome'], right_on = ['Scopus_ID','Cognome','Nome'], indicator=False)

df_new.dropna(inplace=True)

conta=0
df_new['Scopus_ID']=df_new['Scopus_ID'].apply(int)
df_new['Scopus_ID']=df_new['Scopus_ID'].apply(str)

df_Articles = pd.DataFrame(columns = ['Date', 'Articoli', 'DOI','Journal','Authors','Authors_ID','Author','Citations'])
df_new = df_new.reset_index(drop=True)

for ii in range(0,len(df_new)):
    num=df_new['Scopus_ID'][ii]
    print(num)
    conta=conta+1
    print(conta)
    Date=[]
    Articoli=[]
    DOIn=[]
    Journal=[]
    Authors=[]
    Authors_ID=[]
    Author=[]
    Citations=[]
    au = AuthorRetrieval(num)
    documents=au.get_documents(refresh=True)
    if documents is not None:
        for i in range (0,len(documents)):
            Date.append(datetime.strptime(documents[i][16], '%Y-%m-%d'))
            Articoli.append(documents[i][4])
            DOIn.append(documents[i][1])
            Journal.append(documents[i][18])
            Authors.append(documents[i][13])
            Authors_ID.append(documents[i][14])
            Author.append(num)
            Citations.append(documents[i][29])
           
        data = {'Date': Date, 'Articoli': Articoli, 'DOI': DOIn, 'Journal':Journal,
                'Authors':Authors,'Authors_ID':Authors_ID,'Author':Author,'Citations':Citations}
       
        df_Author = pd.DataFrame(data)
        df_Articles=pd.concat([df_Articles, df_Author])
        df_Articles = df_Articles.reset_index(drop=True)
    else:
        print(num+' has no documents')


Artdf=Article_xlsx(df_Articles,path_save)
Researchers_metrics(df_Articles,df,path_save)

generate_report='yes'
generate_report_xSSD='yes'

if generate_report=='yes':
    Genera_Report(path_recent,Artdf,path,path_save)
if generate_report_xSSD=='yes':
    Genera_Report_xSSD(path_recent,Artdf,path,path_save)
    
